---
title: K8S的安全平台 NeuVector
date: 2022-06-03 10:13:16
permalink: /pages/k8s128/
categories:
  - 《K8S》学习笔记
tags:
  - k8s
  - 调优
  - 安全
---

## **前 言**

NeuVector 是业界首个端到端的开源容器安全平台，唯一为容器化工作负载提供企业级零信任安全的解决方案。本文将从以下 5 个方面详细介绍如何部署 NeuVector：

**1.  NeuVector 概览**

**2.  NeuVector 安装**

1. 高可用架构设计
2. 多云安全管理
3. 其他配置

## **1.NeuVector 概览**

NeuVector 致力于保障企业级容器平台安全，可以提供实时深入的容器网络可视化、东西向容器网络监控、主动隔离和保护、容器主机安全以及容器内部安全，容器管理平台无缝集成并且实现应用级容器安全的自动化，适用于各种云环境、跨云或者本地部署等容器生产环境。

2021年， NeuVector 被 SUSE 收购，并在 2022 年 1 月完成开源，[成为业界首个端到端的开源容器安全平台](https://links.jianshu.com/go?to=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzIyMTUwMDMyOQ%3D%3D%26mid%3D2247497361%26idx%3D1%26sn%3D00c0debaf63f3724b95a632ab8ef389a%26chksm%3De8397057df4ef941e74acbfc33721902fd1eb8e71b52e460e16e30ec8c0c3fb217be0a4fced7%26scene%3D21%23wechat_redirect)，唯一为容器化工作负载提供企业级零信任安全的解决方案。

项目地址：[https://github.com/neuvector/neuvector](https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2Fneuvector%2Fneuvector)

本文主要基于 NeuVector 首个开源版 NeuVector:5.0.0-preview.1 进行介绍。

#### **1.1. 架构解析**

![img](https:////upload-images.jianshu.io/upload_images/19330071-a18cc7cdeeb41caa?imageMogr2/auto-orient/strip|imageView2/2/w/944/format/webp)

NeuVector 本身包含 Controller、Enforcer、Manager、Scanner 和 Updater 模块。

- Controller ：整个 NeuVector 的控制模块，API 入口，包括配置下发，高可用主要考虑 Controller 的 HA ，通常建议部署 3 个 Controller 模块组成集群。
- Enforcer ：主要用于安全策略部署下发和执行，DaemonSet 类型会在每个节点部署。
- Manager：提供 web-UI(仅HTTPS) 和 CLI 控制台，供用户管理 NeuVector 。
- Scanner ：对节点、容器、Kubernetes 、镜像进行 CVE 漏洞扫描
- Updater ：cronjob ，用于定期更新 CVE 漏洞库

#### **1.2.主要功能概览**

- 安全漏洞扫描
- 容器网络流量可视化
- 网络安全策略定义
- L7 防火墙
- CICD 安全扫描
- 合规分析

本文重点介绍安装部署，具体功能将在后续文章中深入介绍。

## **2.NeuVector 安装**

安装环境
 软件版本：
 OS：Ubuntu18.04
 Kubernetes：1.20.14
 Rancher：2.5.12
 Docker：19.03.15
 NeuVector：5.0.0-preview.1

#### **2.1. 快速部署**

创建 namespace



```cpp
kubectl create namespace neuvector
```

部署 CRD( Kubernetes 1.19+ 版本)



```ruby
kubectl apply -f https://raw.githubusercontent.com/neuvector/manifests/main/kubernetes/crd-k8s-1.19.yaml
```

部署 CRD(Kubernetes 1.18或更低版本)



```ruby
kubectl apply -f https://raw.githubusercontent.com/neuvector/manifests/main/kubernetes/crd-k8s-1.16.yaml
```

配置 RBAC



```cpp
kubectl create clusterrole neuvector-binding-app --verb=get,list,watch,update --resource=nodes,pods,services,namespaces
kubectl create clusterrole neuvector-binding-rbac --verb=get,list,watch --resource=rolebindings.rbac.authorization.k8s.io,roles.rbac.authorization.k8s.io,clusterrolebindings.rbac.authorization.k8s.io,clusterroles.rbac.authorization.k8s.io
kubectl create clusterrolebinding neuvector-binding-app --clusterrole=neuvector-binding-app --serviceaccount=neuvector:default
kubectl create clusterrolebinding neuvector-binding-rbac --clusterrole=neuvector-binding-rbac --serviceaccount=neuvector:default
kubectl create clusterrole neuvector-binding-admission --verb=get,list,watch,create,update,delete --resource=validatingwebhookconfigurations,mutatingwebhookconfigurations
kubectl create clusterrolebinding neuvector-binding-admission --clusterrole=neuvector-binding-admission --serviceaccount=neuvector:default
kubectl create clusterrole neuvector-binding-customresourcedefinition --verb=watch,create,get --resource=customresourcedefinitions
kubectl create clusterrolebinding  neuvector-binding-customresourcedefinition --clusterrole=neuvector-binding-customresourcedefinition --serviceaccount=neuvector:default
kubectl create clusterrole neuvector-binding-nvsecurityrules --verb=list,delete --resource=nvsecurityrules,nvclustersecurityrules
kubectl create clusterrolebinding neuvector-binding-nvsecurityrules --clusterrole=neuvector-binding-nvsecurityrules --serviceaccount=neuvector:default
kubectl create clusterrolebinding neuvector-binding-view --clusterrole=view --serviceaccount=neuvector:default
kubectl create rolebinding neuvector-admin --clusterrole=admin --serviceaccount=neuvector:default -n neuvector
```

检查是否有以下 RBAC 对象



```csharp
kubectl get clusterrolebinding  | grep neuvector
kubectl get rolebinding -n neuvector | grep neuvector

kubectl get clusterrolebinding  | grep neuvector

neuvector-binding-admission                            ClusterRole/neuvector-binding-admission                            44h
neuvector-binding-app                                  ClusterRole/neuvector-binding-app                                  44h
neuvector-binding-customresourcedefinition             ClusterRole/neuvector-binding-customresourcedefinition             44h
neuvector-binding-nvadmissioncontrolsecurityrules      ClusterRole/neuvector-binding-nvadmissioncontrolsecurityrules      44h
neuvector-binding-nvsecurityrules                      ClusterRole/neuvector-binding-nvsecurityrules                      44h
neuvector-binding-nvwafsecurityrules                   ClusterRole/neuvector-binding-nvwafsecurityrules                   44h
neuvector-binding-rbac                                 ClusterRole/neuvector-binding-rbac                                 44h
neuvector-binding-view                                 ClusterRole/view                                                   44h
```



```csharp
kubectl get rolebinding -n neuvector | grep neuvector
neuvector-admin         ClusterRole/admin            44h
neuvector-binding-psp   Role/neuvector-binding-psp   44h
```

部署 NeuVector

底层 Runtime 为 Docker



```ruby
kubectl apply -f https://raw.githubusercontent.com/neuvector/manifests/main/kubernetes/5.0.0/neuvector-docker-k8s.yaml
```

底层 Runtime 为 Containerd（对于 k3s 和 rke2 可以使用此 yaml 文件）



```ruby
kubectl apply -f https://raw.githubusercontent.com/neuvector/manifests/main/kubernetes/5.0.0/neuvector-containerd-k8s.yaml
```

1.21 以下的 Kubernetes 版本会提示以下错误，将 yaml 文件下载将 batch/v1 修改为 batch/v1beta1



```bash
error: unable to recognize "https://raw.githubusercontent.com/neuvector/manifests/main/kubernetes/5.0.0/neuvector-docker-k8s.yaml": no matches for kind "CronJob" in version "batch/v1"
```

1.20.x cronjob 还处于 beta 阶段，1.21 版本开始 cronjob 才正式 GA 。

默认部署web-ui使用的是loadblance类型的Service，为了方便访问修改为NodePort，也可以通过 Ingress 对外提供服务



```swift
kubectl patch  svc neuvector-service-webui  -n neuvector --type='json' -p '[{"op":"replace","path":"/spec/type","value":"NodePort"},{"op":"add","path":"/spec/ports/0/nodePort","value":30888}]'
```

访问 [https://node_ip:30888](https://links.jianshu.com/go?to=https%3A%2F%2Fnode_ip%3A30888)
 默认密码为 admin/admin



![img](https:////upload-images.jianshu.io/upload_images/19330071-9165398efcb4cef8?imageMogr2/auto-orient/strip|imageView2/2/w/944/format/webp)





点击头像旁的 My profile 页面进入设置页面，设置密码和语言

![img](https:////upload-images.jianshu.io/upload_images/19330071-0bb1763d17fe558c?imageMogr2/auto-orient/strip|imageView2/2/w/944/format/webp)



![img](https:////upload-images.jianshu.io/upload_images/19330071-18a98eb87ae369db?imageMogr2/auto-orient/strip|imageView2/2/w/944/format/webp)





#### **2.2. Helm 部署**

添加 repo



```csharp
helm repo add neuvector https://neuvector.github.io/neuvector-helm/
helm search repo neuvector/core
```

创建 namespace



```cpp
kubectl create namespace neuvector
```

创建 ServiceAccount



```undefined
kubectl create serviceaccount neuvector -n neuvector
```

helm 安装



```cpp
helm install neuvector --namespace neuvector neuvector/core  --set registry=docker.io  --set
tag=5.0.0-preview.1 --set=controller.image.repository=neuvector/controller.preview --
set=enforcer.image.repository=neuvector/enforcer.preview --set 
manager.image.repository=neuvector/manager.preview --set 
cve.scanner.image.repository=neuvector/scanner.preview --set cve.updater.image.repository=neuvector/updater.preview
```

Helm-chart 参数查看：
 [https://github.com/neuvector/neuvector-helm/tree/master/charts/core](https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2Fneuvector%2Fneuvector-helm%2Ftree%2Fmaster%2Fcharts%2Fcore)

## **3. 高可用架构设计**

![img](https:////upload-images.jianshu.io/upload_images/19330071-4dca85a4c438402b?imageMogr2/auto-orient/strip|imageView2/2/w/944/format/webp)

NeuVector-HA 主要需要考虑 Controller 模块的 HA，只要有一个 Controller 处于打开状态，所有数据都将在 3 个副本之间之间同步。

Controller 数据主要存储在 /var/neuvector/ 目录中，但出现 POD 重建或集群重新部署时，会自动从此目录加载备份文件，进行集群恢复。

#### **3.1.部署策略**

NeuVector 官方提供四种 HA 部署模式

![img](https:////upload-images.jianshu.io/upload_images/19330071-f0cb9ec22b21ff96?imageMogr2/auto-orient/strip|imageView2/2/w/944/format/webp)

方式一：不进行任何调度限制，由 Kubernetes 进行自由调度管理管理。

方式二：NeuVector control 组件 (manager,controller）+enforce、scanner组件配置调度 label 限制和污点容忍，与 Kubernetes master 节点部署一起。

方式三：给 Kubernetes 集群中通过 Taint 方式建立专属的 NeuVector 节点，只允许 Neuvector control 组件部署。

方式四：NeuVector control 组件 (manager,controller）配置调度 label 限制和污点容忍，与 Kubernetes master 节点部署一起。k8s-master 不部署 enforce 和 scanner 组件，意味着 master 节点不在接受扫描和策略下发。

以方式二为例，进行部署

给 master 节点打上特定标签



```bash
kubectl label nodes nodename nvcontroller=true
```

获取节点 Taint



```csharp
kubectl get node nodename -o yaml|grep -A 5 taint
```

以 Rancher 部署的节点 master 节点为例



```csharp
taints:
  - effect: NoSchedule
    key: node-role.kubernetes.io/controlplane
    value: "true"
  - effect: NoExecute
    key: node-role.kubernetes.io/etcd
```

编辑部署的 yaml 给 NeuVector-control 组件（manager,controller）添加 nodeSelector 和 tolerations 给 enforce、scanner 组件只添加 tolerations 。

例如以 manager 组件为例：



```cpp
kind: Deployment
metadata:
  name: neuvector-manager-pod
  namespace: neuvector
spec:
  selector:
    matchLabels:
      app: neuvector-manager-pod
  replicas: 1
  template:
    metadata:
      labels:
        app: neuvector-manager-pod
    spec:
      nodeSelector:
        nvcontroller: "true"
      containers:
        - name: neuvector-manager-pod
          image: neuvector/manager.preview:5.0.0-preview.1
          env:
            - name: CTRL_SERVER_IP
              value: neuvector-svc-controller.neuvector
      restartPolicy: Always
      tolerations:
      - effect: NoSchedule
        key: "node-role.kubernetes.io/controlplane"
        operator: Equal
        value: "true"
      - effect: NoExecute
        operator: "Equal"
        key: "node-role.kubernetes.io/etcd"
        value: "true"
```

#### **3.2.数据持久化**

配置环境变量启用配置数据持久化



```objectivec
- env:
  - name: CTRL_PERSIST_CONFIG
```

配置此环境变量后，默认情况下 NeuVector-Controller 会将数据存储在 /var/neuvector 目录内，默认此目录是 hostpath 映射在 POD 所在宿主机的 /var/neuvector 目录内。

若需要更高级别数据可靠性也可以通过 PV 对接 nfs 或其他支出多读写的存储中。

这样当出现 NeuVector-Controller 三个 POD 副本同时都销毁，宿主机都完全不可恢复时，也不会有数据配置数据丢失。

以下以 NFS 为例。

部署 nfs

创建 pv 和 pvc



```ruby
cat <<EOF | kubectl apply -f -

apiVersion: v1
kind: PersistentVolume
metadata:
  name: neuvector-data
spec:
  capacity:
    storage: 10Gi
  accessModes:
    - ReadWriteMany 
  nfs:
    path: /nfsdata
    server: 172.16.0.195 

EOF
cat <<EOF | kubectl apply -f -

kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: neuvector-data
  namespace: neuvector
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 10Gi
EOF
```

修改 NeuVector-Controller 部署 yaml，添加 pvc 信息，将 /var/neuvector 目录映射到 nfs 中（默认是hostpath映射到本地)



```cpp
spec:
  template:
    spec:
      volumes:
        - name: nv-share
#         hostPath:                        // replaced by persistentVolumeClaim
#           path: /var/neuvector        // replaced by persistentVolumeClaim
          persistentVolumeClaim:
            claimName: neuvector-data
```

或直接在 NeuVector 部署 yaml 中挂载 nfs 目录



```jsx
volumes:
      - name: nv-share
        nfs:
          path: /opt/nfs-deployment
          server: 172.26.204.144
```

## **4.多云安全管理**

![img](https:////upload-images.jianshu.io/upload_images/19330071-65a25735ed5d7e6f?imageMogr2/auto-orient/strip|imageView2/2/w/944/format/webp)

在实际生产应用中，会存在对多个集群进行安全进行管理，NeuVector 支持集群联邦功能。

需要在一个集群上暴露 Federation Master 服务，在每个远端集群上部署 Federation Worker 服务。为了更好的灵活性，可以在每个集群同时启用 Federation Master 和 Federation Worker 服务。

在每个集群部署此 yaml



```tsx
apiVersion: v1
kind: Service
metadata:
  name: neuvector-service-controller-fed-master
  namespace: neuvector
spec:
  ports:
  - port: 11443
    name: fed
    nodePort: 30627
    protocol: TCP
  type: NodePort
  selector:
    app: neuvector-controller-pod

---

apiVersion: v1
kind: Service
metadata:
  name: neuvector-service-controller-fed-worker
  namespace: neuvector
spec:
  ports:
  - port: 10443
    name: fed
    nodePort: 31783
    protocol: TCP
  type: NodePort
  selector:
    app: neuvector-controller-pod
```

将其中一个集群升级为主集群

![img](https:////upload-images.jianshu.io/upload_images/19330071-9d6f9fc538a147cc?imageMogr2/auto-orient/strip|imageView2/2/w/944/format/webp)

将其中一个集群升级为主集群，配置连接远程暴露 ip 和对 remot cluster 可达的端口。

![img](https:////upload-images.jianshu.io/upload_images/19330071-8901d694e4a34491?imageMogr2/auto-orient/strip|imageView2/2/w/944/format/webp)

![img](https:////upload-images.jianshu.io/upload_images/19330071-8a4c3813170b0fdb?imageMogr2/auto-orient/strip|imageView2/2/w/944/format/webp)

![img](https:////upload-images.jianshu.io/upload_images/19330071-8261557aee9ac71d?imageMogr2/auto-orient/strip|imageView2/2/w/944/format/webp)

在主集群中，生成 token，用于其他 remote cluster 连接。

![img](https:////upload-images.jianshu.io/upload_images/19330071-bfd79abf0e63ade1?imageMogr2/auto-orient/strip|imageView2/2/w/944/format/webp)

![img](https:////upload-images.jianshu.io/upload_images/19330071-44c2f4fb2b1dffab?imageMogr2/auto-orient/strip|imageView2/2/w/944/format/webp)

在 remote cluster 中配置加入主集群，配置 token 和连接端子

![img](https:////upload-images.jianshu.io/upload_images/19330071-ce8b84b9c471b939?imageMogr2/auto-orient/strip|imageView2/2/w/944/format/webp)

![img](https:////upload-images.jianshu.io/upload_images/19330071-846442347a420812?imageMogr2/auto-orient/strip|imageView2/2/w/944/format/webp)

在界面可以对多个 NeuVector 集群进行管理

![img](https:////upload-images.jianshu.io/upload_images/19330071-a867ab46b459f39b?imageMogr2/auto-orient/strip|imageView2/2/w/944/format/webp)

## **5.其他配置**

#### **5.1.升级**

若是采用 yaml 文件方式部署的 NeuVector 直接更新对应的组件镜像 tag 即可完成升级。如



```bash
kubectl set imagedeployment/neuvector-controller-podneuvector-controller-pod=neuvector/controller:2.4.1 -n neuvector
```



```bash
kubectl set image -n neuvectords/neuvector-enforcer-pod neuvector-enforcer-pod=neuvector/enforcer:2.4.1
```

若是采用 Helm 部署的 NeuVector，则直接执行 helm update 配置对应参数即可。

#### **5.2.卸载**

删除部署的组件



```ruby
kubectl delete -f https://raw.githubusercontent.com/neuvector/manifests/main/kubernetes/5.0.0/neuvector-docker-k8s.yaml
```

删除配置的 RBAC



```dart
kubectl get clusterrolebinding  | grep neuvector|awk '{print $1}'|xargs kubectl delete clusterrolebinding
```



```dart
kubectl get rolebinding -n neuvector | grep neuvector|awk '{print $1}'|xargs kubectl delete rolebinding -n neuvector
```

删除对应的 CRD



```ruby
kubectl delete -f  https://raw.githubusercontent.com/neuvector/manifests/main/kubernetes/5.0.0/crd-k8s-1.19.yaml

kubectl delete -f https://raw.githubusercontent.com/neuvector/manifests/main/kubernetes/5.0.0/waf-crd-k8s-1.19.yaml

kubectl delete -f https://raw.githubusercontent.com/neuvector/manifests/main/kubernetes/5.0.0/admission-crd-k8s-1.19.yaml
```

**总结：**

SUSE 此次开源的 NeuVector 是一个成熟稳定的容器安全管理平台，未来 NeuVector 会和 Rancher 产品更好地融合。



