---
title: 为k8s集群的节点预留计算资源
date: 2022-06-03 10:13:16
permalink: /pages/k8s133/
categories:
  - 《K8S》学习笔记
tags:
  - k8s
  - 调优
---



引用官方：[地址](https://kubernetes.io/docs/tasks/administer-cluster/reserve-compute-resources/#node-allocatable)

## 1、问题描述

业务反馈节点内存才使用了86%的内存，但是describe node出来使用了96%，是因为节点设置了预留内存

```sh
kubectl describe node node-c61q
```

![clipboard](https://cdn.jsdelivr.net/gh/lzq70112/images/blog/202206081652645.png)

![clipboard (1)](https://cdn.jsdelivr.net/gh/lzq70112/images/blog/202206081656663.png)

默认情况下pod能够使用节点全部可用资源。如果用户pod中的应用存在异常，例如疯狂占用内存，那么这些pod将与node上的系统守护进程和k8s组件争夺资源并导致节点资源短缺，从而产生node not ready问题。

```
NodeAllocatable = [NodeCapacity] - [kube-reserved] - [system-reserved] - [eviction-threshold]
```

- Node Capacity：Node的所有硬件资源
- kube-reserved：给kube组件预留的资源
- system-reserved：给System进程预留的资源
- eviction-threshold：kubelet eviction的阈值设定
- Allocatable：真正scheduler调度Pod时的参考值（保证Node上所有Pods的request resource不超过Allocatable）

## 2、原因

k8s设置了`eviction-threshold` 资源的限制

![clipboard](https://cdn.jsdelivr.net/gh/lzq70112/images/blog/202206081709342.png)

## 3、扩展-kubelet添加额外启动参数

可配置在` kubelet /var/lib/kubelet/config.yaml`配置文件，或者`/var/lib/kubelet/kubeadm-flags.env`启动参数

```sh
--enforce-node-allocatable=pods,kube-reserved,system-reserved
#开启为kube组件和系统守护进程预留资源的功能
--kube-reserved-cgroup=/system.slice/kubelet.service
#设置k8s组件的cgroup
--system-reserved-cgroup=/system.slice
#设置系统守护进程的cgroup
--kube-reserved=cpu=200m,memory=250Mi
#配置为k8s组件预留资源的大小，CPU、Mem
--system-reserved=cpu=200m,memory=250Mi
#配置为系统守护进程预留资源的大小（预留的值需要根据机器上容器的密度做一个合理的值）
--eviction-hard=memory.available<5%,nodefs.available<10%,imagefs.available<10%
#驱逐pod的配置：硬阈值（保证95%的内存利用率）
--eviction-soft=memory.available<10%,nodefs.available<15%,imagefs.available<15%
#驱逐pod的配置：软阈值
--eviction-soft-grace-period=memory.available=2m,nodefs.available=2m,imagefs.available=2m
##定义达到软阈值之后，持续时间超过多久才进行驱逐
--eviction-max-pod-grace-period=30
#驱逐pod前最大等待时间=min(pod.Spec.TerminationGracePeriodSeconds, eviction-max-pod-grace-period)，单位秒
--eviction-minimum-reclaim=memory.available= 0Mi,nodefs.available=500Mi,imagefs.available=500Mi
```


当系统内存不足时，就有可能触发系统 OOM，这时候根据 oom score 来确定优先杀死哪个进程，而 oom_score_adj 又是影响 oom score 的重要参数，其值越低，表示 oom 的优先级越低。在计算节点中，进程的 oom_score_adj 如下：



sshd 等 | K8S 管理进程 | guarantee pod | 其它进程 | best effort pod
:-----: | :---: | :---: | :---: | :---: 
具体进程 | sshd／dmevented / systemd-udevd | kubelet / docker / journalctl | guarantee pod | 内核 init 进程等 
oom_score_adj | -1000 | -999 | -998 | 0 



所以，很大概率上，OOM 的优先级如下：
best effort pod > 其它进程 > guarantee pod > kubelet/docker 等 > sshd 等。
如果节点没有 best effort 类型的 pod，那么其它进程就有可能被 OOM，包括系统进程等。

## 4、添加cgroup subsystem

在Kubernetes 1.8版本，kubelet启动会检查以下cgroup subsystem的存在：`cpu、cpuacct、cpuset、memory、systemd`。所以需要确保这些cgroup目录的存在。

```sh
mkdir -p /sys/fs/cgroup/cpu/system.slice/kubelet.service
mkdir -p /sys/fs/cgroup/cpuacct/system.slice/kubelet.service
mkdir -p /sys/fs/cgroup/cpuset/system.slice/kubelet.service
mkdir -p /sys/fs/cgroup/memory/system.slice/kubelet.service
mkdir -p /sys/fs/cgroup/systemd/system.slice/kubelet.service
```

