---

title: ELK收集K8S的log-pilot+es+logstach+kibanan
date: 2020-09-08 10:13:16
permalink: /pages/b5e14521813/
categories:
  - 《elk》学习笔记
tags:
  - k8s
  - elk
---

![image-20210921180354767](https://cdn.jsdelivr.net/gh/lzq70112/images/blog/image-20210921180354767.png)





<!-- more -->

## 1、elasticsearch 说明

------

- elasticsearch可以 使用阿里云的产品 [阿里云 · Elasticsearch](https://data.aliyun.com/product/elasticsearch)

  可以先使用免费版 `1核2G内存20G SSD 三组`

  开通后会有 地址、用户名、密码等信息，这些是要填写在logstash的输出配置文件中

  阿里云和elastic有合作，es有授权，用户管理、用户登录、索引监控、节点监控、logstash监控等功能均可正常使用

  除以上外，定期清理es的索引也很有必要，定时删除过期日志索引文件 

  

**此处ES我们选择自己搭建**

ELK最好由单独的云服务器搭建或者服务器搭建，下面会直接放置在容器中



:::details

elk7.1之后x-pack的密码更新

[elk之间有严格的对应关系](https://www.elastic.co/cn/support/matrix#matrix_compatibility)

:::

## 2、logstash 配置方法

- logstash的三个实例，我是运行在同一台机器上，同时kibana也是运行在这台机器上
- 当然也可以通过一个logstash实例，配置中采用判断条件建立不同索引，但会影响性能，所以这里我起了三个实例
- logstash的主要功能是将收集到的日志进行拆分，采用某些字段建成索引，传递给 `elasticsearch` 集群

### 2.1、logstash 处理k8s日志

- logstash 监控配置文件，监控信息会体现在kibana中

```bash
cat > /data/conf/logstash.yml << EOF
xpack.monitoring.elasticsearch.url: 192.168.2.28:9200
xpack.monitoring.elasticsearch.username: "logstash_system"
xpack.monitoring.elasticsearch.password: "123456"
EOF
```

#### 配置文件

```bash
cat > /data/conf/logstash-k8s.conf << EOF
input {
  beats {
    host => "0.0.0.0"
    port => "5043"
  }
}
filter {
  grok {
    match => { "message" => "%{TIMESTAMP_ISO8601:log-timestamp} %{LOGLEVEL:log-level} %{JAVALOGMESSAGE:log-msg}" }
  }
  mutate {
#    remove_field => ["message"]
    remove_field => ["beat"]
   }
}
output {
  stdout { codec => rubydebug }
  elasticsearch {
        hosts => ["192.168.2.28:9200"]
        user => ["logstash_system"]
        password => ["123456"]
        index => "%{k8s_container_name}-%{+YYYY.MM.dd}"
  }
}
EOF
```

#### 启动命令

```bash
docker run -p 5053:5043 -d \
    --user root \
    --log-driver json-file \
    --log-opt max-size=10m \
    --log-opt max-file=3 \
    --name logstash-k8s \
    --restart=always \
    -v /data/conf/logstash-k8s.conf:/usr/share/logstash/pipeline/logstash.conf \
    -v /data/conf/logstash.yml:/usr/share/logstash/config/logstash.yml \
    logstash:6.6.2
```

### 2.2、logstash 处理docker日志

#### 配置文件

```bash
cat > /data/conf/logstash-docker.conf << EOF
input {
  beats {
    host => "0.0.0.0"
    port => "5043"
  }
}
filter {
  grok {
    match => { "message" => "%{TIMESTAMP_ISO8601:log-timestamp} %{LOGLEVEL:log-level} %{JAVALOGMESSAGE:log-msg}" }
  }
  mutate {
#    remove_field => ["message"]
    remove_field => ["beat"]
   }
}
output {
  stdout { codec => rubydebug }
  elasticsearch {
        hosts => ["192.168.2.28:9200"]
        user => ["logstash_system"]
        password => ["123456"]
        index => "%{docker_container}-%{+YYYY.MM.dd}"
  }
}
EOF
```

#### 启动命令

```bash
docker run -p 5063:5043 -d \
    --user root \
    --log-driver json-file \
    --log-opt max-size=10m \
    --log-opt max-file=3 \
    --name logstash-docker \
    --restart=always \
    -v /data/conf/logstash-docker.conf:/usr/share/logstash/pipeline/logstash.conf \
    -v /data/conf/logstash.yml:/usr/share/logstash/config/logstash.yml \
    logstash:6.6.2
```







## 3、log-pilot的安装

### log-pilot 配置方法

- 在Kubernetes下，可以依据Log-Pilot环境变量aliyun_logs_$name = $path，动态地生成日志采集配置文件，其中包含两个变量：
  - $name 是我们自定义的一个字符串，它在不同的场景下指代不同的含义，在本场景中，将日志采集到 ElasticSearch 的时候，这个 $name 表示的是 Index。
  - 另一个是 $path，支持两种输入形式，stdout 和容器内部日志文件的路径，对应日志标准输出和容器内的日志文件。
  - 第一种约定关键字 stdout 表示的是采集容器的标准输出日志，如本例中我们要采集 tomcat 容器日志，那么我们通过配置标签 aliyun.logs.catalina=stdout 来采集 tomcat 标准输出日志。
  - 第二种是容器内部日志文件的路径，也支持通配符的方式，通过配置环境变量 aliyun_logs_access=/usr/local/tomcat/logs/*.log 来采集 tomcat 容器内部的日志。当然如果你不想使用 aliyun 这个关键字，Log-Pilot 也提供了环境变量 PILOT_LOG_PREFIX 可以指定自己的声明式日志配置前缀，比如 PILOT_LOG_PREFIX: "aliyun,custom"。
- 此外，Log-Pilot 还支持多种日志解析格式，通过 aliyun_logs_$name_format=<format> 标签就可以告诉 Log-Pilot 在采集日志的时候，同时以什么样的格式来解析日志记录，支持的格式包括：none、json、csv、nginx、apache2 和 regxp。
- Log-Pilot 同时支持自定义 tag，我们可以在环境变量里配置 aliyun_logs_$name_tags="K1=V1,K2=V2"，那么在采集日志的时候也会将 K1=V1 和 K2=V2 采集到容器的日志输出中。自定义 tag 可帮助您给日志产生的环境打上 tag，方便进行日志统计、日志路由和日志过滤。



### 3.1、k8s监控



`vim ops-log-pilot-filebeat-ds.yaml`

```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: ops
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: ops-log-pilot-filebeat-ds
  namespace: ops
spec:
  selector:
    matchLabels:
      app: log-pilot-filebeat
      release: stable
  template:
    metadata:
      labels:
        app: log-pilot-filebeat
        release: stable
    spec:
      containers:
      - name: log-pilot-filebeat
        image: registry.cn-hangzhou.aliyuncs.com/acs/log-pilot:0.9.6-filebeat
        env:
        - name: "NODE_NAME"
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        - name: "PILOT_LOG_PREFIX"
          value: "glinux"
        - name: "LOGGING_OUTPUT"
          value: "logstash"
        # 请确保集群到ES网络可达
        - name: "LOGSTASH_HOST"
          value: "192.168.2.22"
        - name: "LOGSTASH_PORT"
          value: "5053"
        volumeMounts:
        - name: sock
          mountPath: /var/run/docker.sock
        - name: root
          mountPath: /host
          readOnly: true
        - name: varlib
          mountPath: /var/lib/filebeat
        - name: varlog
          mountPath: /var/log/filebeat
        - name: localtime
          mountPath: /etc/localtime
          readOnly: true
        livenessProbe:
          failureThreshold: 3
          exec:
            command:
            - /pilot/healthz
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 2
        securityContext:
          capabilities:
            add:
            - SYS_ADMIN
      volumes:
      - name: sock
        hostPath:
          path: /var/run/docker.sock
      - name: root
        hostPath:
          path: /
      - name: varlib
        hostPath:
          path: /var/lib/filebeat
          type: DirectoryOrCreate
      - name: varlog
        hostPath:
          path: /var/log/filebeat
          type: DirectoryOrCreate
      - name: localtime
        hostPath:
          path: /etc/localtime
```

### 3.2、docker监控

```shell
docker run -d \
   --name log-pilot-filebeat \
   -v /var/run/docker.sock:/var/run/docker.sock \
   -v /etc/localtime:/etc/localtime \
   -v /:/host:ro \
   --cap-add SYS_ADMIN \
   -e PILOT_LOG_PREFIX=glinux \
   -e LOGGING_OUTPUT=logstash \
   -e LOGSTASH_HOST=192.168.2.22 \
   -e LOGSTASH_PORT=5063 \
   --restart=always \
   registry.cn-hangzhou.aliyuncs.com/acs/log-pilot:0.9.5-filebeat
```











## 4、kibana 的监控

### 4.1、kibana 的管理

![img-w500](https://img2018.cnblogs.com/blog/1018310/201907/1018310-20190706004902053-1147064113.png)

kibana 说明和配置

------

- 下面步骤操作完毕启动后，此处访问 `http://IP:5603`，用户名和密码同 `elasticserach` 的，输入即可登录kibana，如此建立索引，就可以正常的玩耍了

### 4.2、kibana 配置文件

- 如下的配置文件会屏蔽掉许多没用的插件功能模块，如上图显示的清爽界面

```bash
cat > /data/conf/kibana-es-aliyun.yml << EOF
# Default Kibana configuration from kibana-docker.
server.name: kibana
server.host: "0"
elasticsearch.hosts: 192.168.2.28:9200
elasticsearch.username: kibana
elasticsearch.password: 123456
xpack.monitoring.ui.container.elasticsearch.enabled: true
timelion.enabled: false
console.enabled: false
xpack.grokdebugger.enabled: false
xpack.searchprofiler.enabled: false
xpack.canvas.enabled: false
xpack.ml.enabled: false
xpack.infra.enabled: false
xpack.apm.enabled: false
xpack.graph.enabled: false
EOF
```

### 4.3、kibana 启动命令

```bash
docker run -p 5603:5601 -d \
    --user root \
    --log-driver json-file \
    --log-opt max-size=10m \
    --log-opt max-file=3 \
    --name kibana-es-aliyun \
    --restart=always \
    -e ELASTICSEARCH_URL=http://192.168.2.28:9200 \
    kibana:6.6.2
```

- 下面来看下优秀的登录界面
  ![img-w500](https://img2018.cnblogs.com/blog/1018310/201907/1018310-20190706004919606-2128114853.png)



![image-20210924042738076](https://cdn.jsdelivr.net/gh/lzq70112/images/blog/image-20210924042738076.png)

## 5、日志收集效果验证

------

### 5.1、docker日志收集案例 tomcat

- 注意 `label` 的配置

```bash
   docker run -it -d --name tomcat1 -p 10080:8080 \
    -v /var/logs/:/usr/local/tomcat/logs \
    --label glinux.logs.catalina=stdout \
    --label glinux.logs.access=/usr/local/tomcat/logs/localhost_access_log.*.txt \
    tomcat
```

- 日志收集效果如下图：

- ## ![image-20210924050345834](https://cdn.jsdelivr.net/gh/lzq70112/images/blog/image-20210924050345834.png)5.2、k8s日志收集案例 tomcat

- 注意env的配置

```bash
cat > tomcat-pod.yaml << EOF
apiVersion: v1
kind: Pod
metadata:
  name: tomcat
spec:
  containers:
  - name: tomcat
    image: "tomcat:7.0"
    env:
# 1、stdout为约定关键字，表示采集标准输出日志
# 2、配置标准输出日志采集到ES的catalina索引下
    - name: glinux_logs_catalina
      value: "stdout"
# 1、配置采集容器内文件日志，支持通配符
# 2、配置该日志采集到ES的access索引下
    - name: glinux_logs_access
      value: "/usr/local/tomcat/logs/catalina.*.log"
# 容器内文件日志路径需要配置emptyDir
    volumeMounts:
    - name: tomcat-log
      mountPath: /usr/local/tomcat/logs
  volumes:
  - name: tomcat-log
    emptyDir: {}
EOF

```

调用

`kubectl apply -f tomcat-pod.yaml -n ops`

- 日志收集效果如下图：
- ![image-20210924042549838](https://cdn.jsdelivr.net/gh/lzq70112/images/blog/image-20210924042549838.png)

