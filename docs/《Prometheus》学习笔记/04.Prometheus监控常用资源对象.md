---

title: Prometheus监控常用资源对象
date: 2021-09-08 10:13:16
permalink: /pages/b5e11114/
categories:
  - 《Prometheus》学习笔记
tags:
  - k8s
  - Prometheus
---

Prometheus监控常用资源对象

<!-- more -->

## 1、Prometheus 中来自动监控 Kubernetes 中的一些常用资源对象



在 Prometheus 中用静态的方式来监控 Kubernetes 集群中的普通应用，但是如果针对集群中众多的资源对象都采用静态的方式来进行配置的话显然是不现实的，所以同样我们需要使用到 Prometheus 提供的其他类型的服务发现机制

## 2、cAdvisor容器监控

`cAdvisor`已经内置在了 kubelet 组件之中，所以我们不需要单独去安装，`cAdvisor`的数据路径为`/api/v1/nodes/<node>/proxy/metrics`，同样我们这里使用 node 的服务发现模式，因为每一个节点下面都有 kubelet，自然都有`cAdvisor`采集到的数据指标，配置

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: kube-ops
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      scrape_timeout: 15s
    scrape_configs:
    - job_name: 'prometheus'
      static_configs:
      - targets: ['localhost:9090']
    - job_name: 'redis'
      static_configs:
      - targets: ['redis:9121']
    - job_name: 'kubernetes-nodes'
      kubernetes_sd_configs:
      - role: node
      relabel_configs:
      - source_labels: [__address__]
        regex: '(.*):10250'
        replacement: '${1}:9100'
        target_label: __address__
        action: replace
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
    - job_name: 'kubernetes-kubelet'
      kubernetes_sd_configs:
      - role: node
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
    - job_name: 'kubernetes-cadvisor'
      kubernetes_sd_configs:
      - role: node
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
        replacement: $1
      - source_labels: [__meta_kubernetes_node_name]
        regex: (.+)
        replacement: /metrics/cadvisor    # <nodeip>/metrics -> <nodeip>/metrics/cadvisor
        target_label: __metrics_path__
```

![image-20211002145444956](https://cdn.jsdelivr.net/gh/lzq70112/images/blog/image-20211002145444956.png)

### 2.1、查看

切换到 Graph 路径下面查询容器相关数据，比如我们这里来查询集群中所有 Pod 的 CPU 使用情况，kubelet 中的 cAdvisor 采集的指标和含义，可以查看 [Monitoring cAdvisor with Prometheus](https://github.com/google/cadvisor/blob/master/docs/storage/prometheus.md) 说明，其中有一项：



`container_cpu_usage_seconds_total` 是容器累计使用的 CPU 时间，用它除以 CPU 的总时间，就可以得到容器的 CPU 使用率了：

`sum(rate(container_cpu_usage_seconds_total{image!="",pod!=""}[1m])) by (namespace, pod)`

选择标签并填入公式

![image-20211002150027429](https://cdn.jsdelivr.net/gh/lzq70112/images/blog/image-20211002150027429.png)

:::warning

在 Kubernetes 1.16 版本中移除了 cadvisor metrics 的 pod_name 和 container_name 这两个标签，改成了 pod 和 container。

:::

**容器的cpu使用率**

```
(sum(rate(container_cpu_usage_seconds_total{image!="",pod!=""}[1m])) by (namespace, pod))
/
(sum(container_spec_cpu_quota{image!="", pod!=""}) by(namespace, pod) / 100000) * 100
```

![image-20211002152754601](https://cdn.jsdelivr.net/gh/lzq70112/images/blog/image-20211002152754601.png)

**pod的cpu使用率**

```
sum(container_memory_rss{image!=""}) by(namespace, pod) / sum(container_spec_memory_limit_bytes{image!=""}) by(namespace, pod) * 100 != +inf
```

## 3、node_exporter实现api-server监控



apiserver 作为 Kubernetes 最核心的组件，当然他的监控也是非常有必要的，对于 apiserver 的监控我们可以直接通过 kubernetes 的 Service 来获取：

```bash
$ kubectl get svc
NAME             TYPE           CLUSTER-IP       EXTERNAL-IP             PORT(S)          AGE
kubernetes       ClusterIP      10.96.0.1        <none>                  443/TCP          33d
```



上面这个 Service 就是我们集群的 apiserver 在集群内部的 Service 地址，要自动发现 Service 类型的服务，我们就需要用到 role 为 Endpoints 的 `kubernetes_sd_configs`，我们可以在 ConfigMap 对象中添加上一个 Endpoints 类型的服务的监控任务：

```yaml
    - job_name: 'kubernetes-apiservers'
      kubernetes_sd_configs:
      - role: endpoints
      # 抓取所有ep，也就是所有的service
```



上面这个任务是定义的一个类型为 endpoints 的 kubernetes_sd_configs ，添加到 Prometheus 的 ConfigMap 的配置文件中，然后更新配置：

`curl -X POST "http://10.244.3.174:9090/-/reload"`

更新完成后，我们再去查看 Prometheus 的 Dashboard 的 target 页面：

![image-20211002165648226](https://cdn.jsdelivr.net/gh/lzq70112/images/blog/image-20211002165648226.png)

我们可以看到 kubernetes-apiservers 下面出现了很多实例，这是因为这里我们使用的是 Endpoints 类型的服务发现的所以 Prometheus 把所有的 Endpoints 服务都抓取过来了。

怎样来过滤出单个服务来呢？ `relabel_configs` 这里不是使用 `replace` 这个动作了，而是 `keep`，就是只把符合我们要求的给保留下来.





哪些才是符合我们要求的呢？我们可以把鼠标放置在任意一个 target 

![image-20211002170251242](https://cdn.jsdelivr.net/gh/lzq70112/images/blog/image-20211002170251242.png)

上可以查看到`Before relabeling`里面所有的元数据，比如我们要过滤的服务是 `default` 这个 namespace 下面，服务名为 `kubernetes` 的元数据，所以这里我们就可以根据对应的 `__meta_kubernetes_namespace` 和 `__meta_kubernetes_service_name` 这两个元数据来 relabel，另外由于 kubernetes 这个服务对应的端口是 443，需要使用 https 协议，所以这里我们需要使用 https 的协议，对应的就需要将 ca 证书配置上，如下所示：

```yaml
    - job_name: 'kubernetes-apiservers'
      kubernetes_sd_configs:
      - role: endpoints
      # 抓取所有ep，也就是所有的service
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      relabel_configs:
      - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
        action: keep
        # 过滤服务
        regex: default;kubernetes;https
        # 匹配字段
```



现在重新更新配置文件、重新加载 Prometheus，切换到 Prometheus 的 Targets 路径下查看：

![image-20211002184626380](https://cdn.jsdelivr.net/gh/lzq70112/images/blog/image-20211002184626380.png)

现在可以看到 `kubernetes-apiserver` 这个任务下面只有 apiserver 实例了



现在我们切换到 Graph 路径下面查看下采集到的数据，比如查询 apiserver 的总的请求数：

`sum(rate(apiserver_request_duration_seconds_count[1m]))`

![image-20211002185258618](https://cdn.jsdelivr.net/gh/lzq70112/images/blog/image-20211002185258618.png)

这样我们就完成了对 Kubernetes APIServer 的监控。

另外如果我们要来监控其他系统组件，比如 kube-controller-manager、kube-scheduler 的话应该怎么做呢？

由于 apiserver 服务 namespace 在 default 使用默认的 Service kubernetes，

而其余组件服务在 kube-system 这个 namespace 下面，如果我们想要来监控这些组件的话，需要手动创建单独的 Service，其中 

kube-sheduler 的指标数据端口为 10251

kube-controller-manager 对应的端口为 10252

## 4、自动发现监控pod

配置一个任务用来专门发现普通类型的 Endpoint，其实就是 Service 关联的 Pod 列表：

```yaml
    - job_name: 'kubernetes-endpoints'
      kubernetes_sd_configs:
      - role: endpoints
      relabel_configs:
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
        action: keep
        regex: true
        #  保留的主要是prometheus.io/scrape: "true"的pod
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]
        action: replace
        target_label: __scheme__
        regex: (https?)
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
        action: replace
        target_label: __address__
        regex: ([^:]+)(?::\d+)?;(\d+)  # RE2 正则规则，+是一次多多次，?是0次或1次，其中?:表示非匹配组(意思就是不获取匹配结果)
        replacement: $1:$2
      - action: labelmap
        regex: __meta_kubernetes_service_label_(.+)
      - source_labels: [__meta_kubernetes_namespace]
        action: replace
        target_label: kubernetes_namespace
      - source_labels: [__meta_kubernetes_service_name]
        action: replace
        target_label: kubernetes_name
      - source_labels: [__meta_kubernetes_pod_name]
        action: replace
        target_label: kubernetes_pod_name
```



![image-20211002191040820](https://cdn.jsdelivr.net/gh/lzq70112/images/blog/image-20211002191040820.png)



` kubectl get svc node-local-dns -n kube-system -o yaml`

```yaml
  annotations:
    prometheus.io/scrape: "true"
```

**监控资源抓取如下**

K8S默认开启的只有DNS的pod

![image-20211002190943786](https://cdn.jsdelivr.net/gh/lzq70112/images/blog/image-20211002190943786.png)

## 5、自动发现监控redis

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis
  namespace: kube-ops
spec:
  selector:
    matchLabels:
      app: redis
  template:
    metadata:
      labels:
        app: redis
    spec:
      containers:
      - name: redis
        image: redis:4
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379
      - name: redis-exporter
        image: oliver006/redis_exporter:latest
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 9121
---
kind: Service
apiVersion: v1
metadata:
  name: redis
  namespace: kube-ops
  annotations:
    prometheus.io/scrape: "true"
    # 主要是加入这条
    prometheus.io/port: "9121"
spec:
  selector:
    app: redis
  ports:
  - name: redis
    port: 6379
    targetPort: 6379
  - name: prom
    port: 9121
    targetPort: 9121                         
```

![image-20211002201740105](https://cdn.jsdelivr.net/gh/lzq70112/images/blog/image-20211002201740105.png)

## 6、监控kube-state-metrics

监控数据都是应用内部的监控，需要应用本身提供一个 `/metrics` 接口，或者对应的 exporter 来暴露对应的指标数据



但是在 Kubernetes 集群上 Pod、DaemonSet、Deployment、Job、CronJob 等各种资源对象的状态也需要监控，这也反映了使用这些资源部署的应用的状态。

- 我调度了多少个副本？现在可用的有几个？
- 多少个 Pod 是 `running/stopped/terminated` 状态？
- Pod重启了多少次？
- 我有多少 job 在运行中等等

Kubernetes 提供了一个[kube-state-metrics](https://github.com/kubernetes/kube-state-metrics) 就是我们需要的



**与 metric-server 的对比**

- `metric-server` 是从 APIServer 中获取cpu、内存使用率这种监控指标，并把他们发送给存储后端，如 influxdb 或云厂商，当前的核心作用是为 HPA 等组件提供决策指标支持。
- `kube-state-metrics` 关注于获取 Kubernetes 各种资源的最新状态，如 deployment 或者 daemonset，metric-server仅仅是获取、格式化现有数据，写入特定的存储，实质上是一个监控系统。而 kube-state-metrics 是获取集群最新的指标。
- 像 Prometheus 这种监控系统，并不会去用 metric-server 中的数据，他都是自己做指标收集、集成的，但 Prometheus 可以监控 metric-server 本身组件的监控状态并适时报警，这里的监控就可以通过 `kube-state-metrics` 来实现，如 metric-server pod 的运行状态。

**安装**

版本兼容情况

![img](https://cdn.jsdelivr.net/gh/lzq70112/images/blog/20210316152109.png)

```bash
git clone https://github.com/kubernetes/kube-state-metrics.git
cd kube-state-metrics/examples/standard
```



`vim deployment.yaml `

```yaml
      containers:
      - image: cnych/kube-state-metrics:v2.0.0-rc.0
      # 修改镜像源
```

配置

```yaml
# service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/name: kube-state-metrics
    app.kubernetes.io/version: 2.0.0-rc.0
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "8080"
    # 8081是kube-state-metrics应用本身指标的端口
  name: kube-state-metrics
  namespace: kube-system
```

`kubectl apply -f .`

**查看自动发现**

![image-20211002232450497](https://cdn.jsdelivr.net/gh/lzq70112/images/blog/image-20211002232450497.png)

